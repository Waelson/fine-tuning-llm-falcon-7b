{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "zz4VkUe5SGks"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets accelerate peft bitsandbytes torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L3gGzf-8SZF5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer\n",
        "from datasets import Dataset\n",
        "from peft import get_peft_model, LoraConfig, TaskType"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXfj9_soSpPI"
      },
      "outputs": [],
      "source": [
        "# Nome do modelo\n",
        "MODEL_NAME = \"tiiuae/falcon-7b\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "qnB78q6qStP1"
      },
      "outputs": [],
      "source": [
        "# Carregar o tokenizador\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pe1SXyvgY_Hs"
      },
      "outputs": [],
      "source": [
        "tokenizer.pad_token = tokenizer.eos_token # Usar o token de EOS para padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xXzkXRl-Sw1e"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Carregar o modelo com quantiza√ß√£o para economizar mem√≥ria\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    torch_dtype=torch.float16,  # Usa menos VRAM\n",
        "    device_map=\"auto\"  # Distribui automaticamente entre CPU e GPU\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n83A_dzjS0EE"
      },
      "outputs": [],
      "source": [
        "# Dados de treino\n",
        "data = [\n",
        "    {\"input\": \"O que √© Golang?\", \"output\": \"Golang, ou Go, √© uma linguagem de programa√ß√£o criada pelo Google em 2007, focada em desempenho, concorr√™ncia e simplicidade.\"},\n",
        "    {\"input\": \"Quais s√£o as principais caracter√≠sticas do Golang?\", \"output\": \"Golang √© conhecido por sua sintaxe simples, garbage collection eficiente, suporte nativo √† concorr√™ncia e compila√ß√£o r√°pida.\"},\n",
        "    {\"input\": \"O que s√£o goroutines em Golang?\", \"output\": \"Goroutines s√£o fun√ß√µes ou m√©todos executados de forma concorrente em Go, sendo mais leves que threads do sistema operacional.\"},\n",
        "    {\"input\": \"Como criar uma goroutine em Go?\", \"output\": \"Basta usar a palavra-chave 'go' antes de chamar uma fun√ß√£o, como em 'go minhaFuncao()'.\"},\n",
        "    {\"input\": \"O que √© um canal (channel) em Golang?\", \"output\": \"Canais s√£o estruturas de comunica√ß√£o entre goroutines, permitindo a troca segura de dados concorrentes.\"},\n",
        "    {\"input\": \"Qual √© a diferen√ßa entre um buffer e um canal sem buffer em Golang?\", \"output\": \"Canais sem buffer bloqueiam o envio at√© que haja um receptor, enquanto canais com buffer armazenam mensagens at√© o limite do buffer.\"},\n",
        "    {\"input\": \"Como declarar uma vari√°vel em Golang?\", \"output\": \"Use 'var nome tipo' ou ':=' para infer√™ncia de tipo, como 'var idade int' ou 'idade := 25'.\"},\n",
        "    {\"input\": \"Golang √© uma linguagem compilada ou interpretada?\", \"output\": \"Golang √© uma linguagem compilada, gerando bin√°rios execut√°veis sem necessidade de uma m√°quina virtual.\"},\n",
        "    {\"input\": \"O que s√£o interfaces em Golang?\", \"output\": \"Interfaces definem um conjunto de m√©todos que um tipo deve implementar, permitindo polimorfismo sem heran√ßa.\"},\n",
        "    {\"input\": \"Como funciona o gerenciamento de mem√≥ria em Golang?\", \"output\": \"Go possui um garbage collector que gerencia automaticamente a aloca√ß√£o e desaloca√ß√£o de mem√≥ria.\"},\n",
        "    {\"input\": \"O que √© um struct em Golang?\", \"output\": \"Structs s√£o tipos compostos que agrupam m√∫ltiplos campos de dados, semelhantes a classes, mas sem heran√ßa.\"},\n",
        "    {\"input\": \"Como definir um struct em Go?\", \"output\": \"Use a palavra-chave 'type' seguida do nome e dos campos, como 'type Pessoa struct { Nome string; Idade int }'.\"},\n",
        "    {\"input\": \"Go suporta orienta√ß√£o a objetos?\", \"output\": \"Go n√£o possui classes nem heran√ßa, mas suporta composi√ß√£o via structs e interfaces.\"},\n",
        "    {\"input\": \"Como tratar erros em Golang?\", \"output\": \"Go usa a abordagem expl√≠cita de erros, retornando valores 'error' em fun√ß√µes e verificando com 'if err != nil'.\"},\n",
        "    {\"input\": \"Como declarar e utilizar um array em Go?\", \"output\": \"Arrays s√£o declarados com 'var a [5]int' e t√™m tamanho fixo, sendo acessados via √≠ndices.\"},\n",
        "    {\"input\": \"O que s√£o slices em Golang?\", \"output\": \"Slices s√£o abstra√ß√µes flex√≠veis sobre arrays, permitindo redimensionamento din√¢mico e melhor gerenciamento de mem√≥ria.\"},\n",
        "    {\"input\": \"Qual a diferen√ßa entre array e slice em Go?\", \"output\": \"Arrays t√™m tamanho fixo, enquanto slices s√£o refer√™ncias a arrays e podem crescer dinamicamente.\"},\n",
        "    {\"input\": \"Como inicializar um map em Go?\", \"output\": \"Use 'make(map[string]int)' ou 'map[string]int{'chave': 10}' para criar um dicion√°rio de chave-valor.\"},\n",
        "    {\"input\": \"Go tem suporte para exce√ß√µes?\", \"output\": \"Go n√£o possui exce√ß√µes como Java ou Python, mas usa 'panic' e 'recover' para capturar falhas cr√≠ticas.\"},\n",
        "    {\"input\": \"Como funciona defer em Go?\", \"output\": \"O 'defer' adia a execu√ß√£o de uma fun√ß√£o at√© o final do escopo atual, √∫til para liberar recursos como arquivos.\"},\n",
        "    {\"input\": \"O que √© o pacote fmt em Go?\", \"output\": \"O pacote 'fmt' fornece fun√ß√µes para formata√ß√£o e impress√£o de strings, como 'fmt.Println()'.\"},\n",
        "    {\"input\": \"O que √© reflection em Golang?\", \"output\": \"Reflection permite inspecionar e modificar tipos e valores em tempo de execu√ß√£o, usando o pacote 'reflect'.\"},\n",
        "    {\"input\": \"O que √© um ponteiro em Go?\", \"output\": \"Ponteiros armazenam endere√ßos de mem√≥ria, permitindo modificar valores sem c√≥pia.\"},\n",
        "    {\"input\": \"Como criar um ponteiro em Go?\", \"output\": \"Use '&' para obter o endere√ßo de uma vari√°vel e '*' para acessar o valor, como 'var p *int = &x'.\"},\n",
        "    {\"input\": \"Go possui gen√©ricos?\", \"output\": \"Desde a vers√£o Go 1.18, a linguagem suporta gen√©ricos, permitindo fun√ß√µes e estruturas de dados flex√≠veis sem perda de tipo.\"},\n",
        "    {\"input\": \"Como instalar pacotes externos em Go?\", \"output\": \"Use 'go get' seguido da URL do pacote, como 'go get github.com/gorilla/mux'.\"},\n",
        "    {\"input\": \"Como definir uma constante em Go?\", \"output\": \"Use a palavra-chave 'const', como em 'const Pi = 3.14'.\"},\n",
        "    {\"input\": \"Como criar um servidor HTTP em Go?\", \"output\": \"Use o pacote 'net/http' e a fun√ß√£o 'http.ListenAndServe()' para criar um servidor web simples.\"},\n",
        "    {\"input\": \"Quais s√£o os comandos b√°sicos do Go Modules?\", \"output\": \"'go mod init' cria um m√≥dulo, 'go mod tidy' limpa depend√™ncias e 'go list -m all' lista os pacotes instalados.\"}\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bc3dCiLlS9C2"
      },
      "outputs": [],
      "source": [
        "# Converter para Dataset Hugging Face\n",
        "dataset = Dataset.from_list(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYt4TpEbS-O2"
      },
      "outputs": [],
      "source": [
        "# Tokenizar e criar labels\n",
        "def tokenize_function(examples):\n",
        "    prompt = \"Pergunta: \" + examples[\"input\"] + \"\\nResposta: \" + examples[\"output\"]\n",
        "\n",
        "    # Tokenizar entrada e sa√≠da juntas\n",
        "    tokens = tokenizer(prompt, truncation=True, padding=\"max_length\", max_length=512)\n",
        "\n",
        "    # Criar labels: r√≥tulos s√£o os mesmos input_ids, mas ignoramos o padding (-100)\n",
        "    tokens[\"labels\"] = tokens[\"input_ids\"].copy()\n",
        "    tokens[\"labels\"] = [\n",
        "        -100 if token == tokenizer.pad_token_id else token for token in tokens[\"labels\"]\n",
        "    ]\n",
        "\n",
        "    return tokens\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_rBgTj1YTDGh"
      },
      "outputs": [],
      "source": [
        "# Tokenizar o dataset\n",
        "dataset = dataset.map(tokenize_function) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ys3_R6ONTHMP"
      },
      "outputs": [],
      "source": [
        "# Configurar LoRA\n",
        "lora_config = LoraConfig(\n",
        "    r=8,  # Define o tamanho das matrizes auxiliares LoRA\n",
        "    lora_alpha=32,  # Define a escala do ajuste LoRA\n",
        "    lora_dropout=0.05,  # Adiciona dropout para evitar overfitting\n",
        "    bias=\"none\", # Remove o bias para economizar mem√≥ria\n",
        "    task_type=TaskType.CAUSAL_LM  # Define o modelo como um \"causal language model\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fc28x0WOTN3-"
      },
      "outputs": [],
      "source": [
        "# Aplicar LoRA ao Falcon 7B\n",
        "model = get_peft_model(model, lora_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTFv5h9HTOxG"
      },
      "outputs": [],
      "source": [
        "# Exibir os par√¢metros trein√°veis do modelo\n",
        "model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_cCmoJu9TiGp"
      },
      "outputs": [],
      "source": [
        "# Configurar os hiperpar√¢metros do treinamento\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./falcon-7b-lora-finetuned\",  # Onde salvar o modelo treinado\n",
        "    per_device_train_batch_size=2,  # Usa batch pequeno para economizar VRAM\n",
        "    gradient_accumulation_steps=4,  # Simula batch maior sem estourar a VRAM\n",
        "    num_train_epochs=3,  # N√∫mero de √©pocas de treinamento\n",
        "    learning_rate=2e-5,  # Taxa de aprendizado otimizada para LoRA (0.00002)\n",
        "    logging_dir=\"./logs\",  # Diret√≥rio de logs para an√°lise\n",
        "    logging_steps=10,  # Salvar logs a cada 10 steps\n",
        "    save_strategy=\"epoch\",  # Salvar checkpoints no final de cada √©poca\n",
        "    fp16=True,  # Usa FP16 para reduzir o consumo de VRAM\n",
        "    push_to_hub=False,  # Se quiser salvar no Hugging Face, mude para True\n",
        "    report_to=\"none\"  # üöÄ Isso desativa o W&B corretamente!\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5GvbXBXTsJc"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset\n",
        ")\n",
        "\n",
        "# Iniciar o treinamento\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIeIL2-BTydM"
      },
      "outputs": [],
      "source": [
        "# Salvar modelo treinado\n",
        "model.save_pretrained(\"./falcon-7b-lora-finetuned\") # Salva o modelo\n",
        "tokenizer.save_pretrained(\"./falcon-7b-lora-finetuned\") # Salva o tokenizador"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yEiK2JUkT-pj"
      },
      "outputs": [],
      "source": [
        "input_text = \"O que √© Golang?\"\n",
        "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(\"cuda\") # Tokenizar e mover para GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-iXD0vAFUJzF"
      },
      "outputs": [],
      "source": [
        "# Gerar resposta com o modelo treinado\n",
        "output = model.generate(\n",
        "    input_ids, # Entrada\n",
        "    attention_mask=input_ids.ne(tokenizer.pad_token_id), # Ignorar padding\n",
        "    max_length=50, # Tamanho m√°ximo da resposta\n",
        "    temperature=0.5, # Controla a aleatoriedade da resposta\n",
        "    top_p=0.9, # Controla a diversidade da resposta\n",
        "    repetition_penalty=1.2,  # Penaliza palavras repetidas\n",
        "    do_sample=True # Habilita a amostragem\n",
        ")\n",
        "\n",
        "generated_text = tokenizer.decode(output[0], skip_special_tokens=True) # Decodifica e remove tokens especiais\n",
        "\n",
        "print(\"\\nüîπ Resposta Gerada:\\n\", generated_text)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
